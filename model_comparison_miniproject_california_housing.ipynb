{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_comparison_miniproject_california_housing.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ayd7Ep4p90B",
        "colab_type": "text"
      },
      "source": [
        "# Model Comparison Mini Project - California Housing\n",
        "\n",
        "This project will compare the performance of various models on the task of prediciting the value of a real estate property as observed in the popular California Housing Data Set. \n",
        "\n",
        "To limit the scope of this project we shall be using a pre-cleaned dataset that does not show any missing value or null values. \n",
        "\n",
        "Any other data preprocessing such as scaling however is not performed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T246DzLhsM-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "\n",
        "#importing required models and model methods as required\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import plot_tree\n",
        "import graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GD1XsPm6Loy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting data\n",
        "# I have combined the classicially available test and training sets into a single dataframe\n",
        "# I have done this so during splitting I can shuffle the data as per my needs to tune performance\n",
        "# the .append function can be used to combine the two sets available in sklearn library\n",
        "# When using colab, the data sets are available in the Sample Data repo under the Files section of your notebook\n",
        "\n",
        "df = pd.read_csv(\"california_housing_full.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUHfNb2UC_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "271e82ab-cd16-4a74-ca09-128320a1bbe3"
      },
      "source": [
        "#let's take a look at the data\n",
        "df.head()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  longitude  ...  median_income  median_house_value\n",
              "0           0    -114.31  ...         1.4936             66900.0\n",
              "1           1    -114.47  ...         1.8200             80100.0\n",
              "2           2    -114.56  ...         1.6509             85700.0\n",
              "3           3    -114.57  ...         3.1917             73400.0\n",
              "4           4    -114.57  ...         1.9250             65500.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPuDEjmbUIL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e413a945-a3fc-4668-f877-2ec045599912"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 10 columns):\n",
            "Unnamed: 0            20000 non-null int64\n",
            "longitude             20000 non-null float64\n",
            "latitude              20000 non-null float64\n",
            "housing_median_age    20000 non-null float64\n",
            "total_rooms           20000 non-null float64\n",
            "total_bedrooms        20000 non-null float64\n",
            "population            20000 non-null float64\n",
            "households            20000 non-null float64\n",
            "median_income         20000 non-null float64\n",
            "median_house_value    20000 non-null float64\n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 1.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzKZd6VkUKub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "823cbd5f-9125-4536-815b-fb7f1d294381"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7449.500000</td>\n",
              "      <td>-119.566172</td>\n",
              "      <td>35.626750</td>\n",
              "      <td>28.627750</td>\n",
              "      <td>2637.051550</td>\n",
              "      <td>537.991800</td>\n",
              "      <td>1425.557650</td>\n",
              "      <td>499.525450</td>\n",
              "      <td>3.872132</td>\n",
              "      <td>207082.716750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5179.978268</td>\n",
              "      <td>2.003609</td>\n",
              "      <td>2.136141</td>\n",
              "      <td>12.582229</td>\n",
              "      <td>2176.314757</td>\n",
              "      <td>420.631119</td>\n",
              "      <td>1131.048487</td>\n",
              "      <td>381.729517</td>\n",
              "      <td>1.900356</td>\n",
              "      <td>115557.055856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>14999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2499.750000</td>\n",
              "      <td>-121.790000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1451.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>788.000000</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>2.562500</td>\n",
              "      <td>119800.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6999.500000</td>\n",
              "      <td>-118.490000</td>\n",
              "      <td>34.250000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>1166.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>3.536000</td>\n",
              "      <td>179800.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11999.250000</td>\n",
              "      <td>-118.000000</td>\n",
              "      <td>37.710000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3149.000000</td>\n",
              "      <td>647.000000</td>\n",
              "      <td>1724.000000</td>\n",
              "      <td>604.000000</td>\n",
              "      <td>4.745325</td>\n",
              "      <td>265000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>16999.000000</td>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>37937.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>500001.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0     longitude  ...  median_income  median_house_value\n",
              "count  20000.000000  20000.000000  ...   20000.000000        20000.000000\n",
              "mean    7449.500000   -119.566172  ...       3.872132       207082.716750\n",
              "std     5179.978268      2.003609  ...       1.900356       115557.055856\n",
              "min        0.000000   -124.350000  ...       0.499900        14999.000000\n",
              "25%     2499.750000   -121.790000  ...       2.562500       119800.000000\n",
              "50%     6999.500000   -118.490000  ...       3.536000       179800.000000\n",
              "75%    11999.250000   -118.000000  ...       4.745325       265000.000000\n",
              "max    16999.000000   -114.310000  ...      15.000100       500001.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnRCvks6Rvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining features\n",
        "x = df.iloc[:,:-1]\n",
        "#defining targets\n",
        "y = df.iloc[:,-1:]\n",
        "\n",
        "#splitting the data\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNS5RQHO67ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c123f114-3464-426d-82c5-9c7748f62649"
      },
      "source": [
        "#Fitting Linear Regressor\n",
        "\n",
        "LR = LinearRegression()\n",
        "LR.fit(xtrain,ytrain)\n",
        "\n",
        "\n",
        "traininglossLR = LR.score(xtrain,ytrain)\n",
        "testinglossLR = LR.score(xtest,ytest)\n",
        "print(traininglossLR)\n",
        "print(testinglossLR)\n",
        "\n",
        "#print(LR.get_params())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6388938078906676\n",
            "0.6518185676146591\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrmGH3qA-Gq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72e99f6f-85fe-4548-a322-81615a6c6ccc"
      },
      "source": [
        "#Using Ridge Regression (L2 regularisation)\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridgeLR = Ridge(alpha = 1)\n",
        "ridgeLR.fit(xtrain,ytrain)\n",
        "\n",
        "\n",
        "traininglossridgeLR = ridgeLR.score(xtrain,ytrain)\n",
        "testinglossridgeLR = ridgeLR.score(xtest,ytest)\n",
        "\n",
        "print(traininglossridgeLR)\n",
        "print(testinglossridgeLR)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6388938053782709\n",
            "0.6518172539668234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtRWjzJ_BEQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7287c478-c5ae-4ccc-8231-7a7d05e8ad3d"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lassoLR = Ridge(alpha = 1)\n",
        "lassoLR.fit(xtrain,ytrain)\n",
        "\n",
        "traininglosslassoLR = lassoLR.score(xtrain,ytrain)\n",
        "testinglosslassoLR = lassoLR.score(xtest,ytest)\n",
        "\n",
        "print(traininglosslassoLR)\n",
        "print(testinglosslassoLR)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6388938053782709\n",
            "0.6518172539668234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iQ1NrF3770F",
        "colab_type": "text"
      },
      "source": [
        "**Analysis on using Linear Regression**\n",
        "\n",
        "**Vanilla version of LR -**\n",
        "\n",
        "Training loss : 0.6388938079\n",
        "\n",
        "Testing loss  : 0.6518185676146591\n",
        "\n",
        "\n",
        "**Ride Regression L2 -**\n",
        " \n",
        "0.6388938053782709\n",
        "\n",
        "0.6518172539668234\n",
        "\n",
        "\n",
        "**Lasso Regression l1 -**\n",
        "\n",
        "0.6388938053782709\n",
        "\n",
        "0.6518172539668234\n",
        "\n",
        "\n",
        "**Analysis -**\n",
        "\n",
        "Although linear regression does not fit the data very well, it will not show high degree of variance, that is if we retrain the model on the same data on each such training iteration the model will perform almost the same. \n",
        "\n",
        "However complex models will although fit the data better, they will show high degree of variance that is the will perform differently after re-training on same data and also if the data changes slightly. \n",
        "\n",
        "Below is an example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47whcE-Cp5M",
        "colab_type": "text"
      },
      "source": [
        "# Using Ransac Regressor\n",
        "\n",
        "RANSAC (RANdom SAmple Consensus) algorithm.\n",
        "\n",
        "RANSAC is an iterative algorithm for the robust estimation of parameters from a subset of inliers from the complete data set. More information can be found in the general documentation of linear models.\n",
        "\n",
        "**We are going to run Ransac multiple times and record observations**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT7DESEb7wd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2849bceb-1d90-425e-c05e-3b58f8f61060"
      },
      "source": [
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "ransacR = RANSACRegressor()\n",
        "ransacR.fit(xtrain, ytrain)\n",
        "\n",
        "#ransacR.score(xtrain,ytrain)\n",
        "traininglossransacR = ransacR.score(xtrain,ytrain)\n",
        "testinglossransacR = ransacR.score(xtest,ytest)\n",
        "\n",
        "print(traininglossransacR)\n",
        "print(testinglossransacR)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.38215269021569\n",
            "0.7119229578158638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSUGqI3_DX3e",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "Iteration 1 - \n",
        "\n",
        "0.40279365680595725\n",
        "\n",
        "0.5978635223695535\n",
        "\n",
        "Iteration 2 - \n",
        "\n",
        "0.4895082652701116\n",
        "\n",
        "\n",
        "0.6170210282185535\n",
        "\n",
        "Iteration 3 - **Best fit**\n",
        "\n",
        "0.5582286892065771\n",
        "\n",
        "0.767279356068632\n",
        "\n",
        "Iteration 4 - \n",
        "\n",
        "0.41852707293959845\n",
        "\n",
        "0.6489107521146353\n",
        "\n",
        "Accuracy of saved and loaded model\n",
        "0.7119229578158638"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d5Qr4vYFTj0",
        "colab_type": "text"
      },
      "source": [
        "# Saving Models\n",
        "When working with complex models, its better to save the best model for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmCfq4teCLS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the model using pickle\n",
        "\n",
        "import pickle\n",
        "\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(ransacR, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxpipMzoErau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "135b8a7d-0a6a-46e8-a7ce-e7a6895bf211"
      },
      "source": [
        "#Loading and using a pre-saved model\n",
        "\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(xtest, ytest)\n",
        "print(result)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7119229578158638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDBE0YRsF4lp",
        "colab_type": "text"
      },
      "source": [
        "# **Using one of the most complex models**\n",
        "\n",
        "The magic with decision trees is that although this algorithm fits the data very optimistically we have the capability to prune the tree and prevent it from overfitting data to our own liking. Meaning we have the ability to define how complex we want the model to be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJURmpNjFrdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3ecc099d-8e40-4176-b3b8-8207025f0188"
      },
      "source": [
        "dtree = DecisionTreeRegressor(max_depth = 15)\n",
        "dtree.fit(xtrain,ytrain)\n",
        "\n",
        "#ransacR.score(xtrain,ytrain)\n",
        "traininglossdtree = dtree.score(xtrain,ytrain)\n",
        "testinglossdtree = dtree.score(xtest,ytest)\n",
        "\n",
        "print(traininglossdtree)\n",
        "print(testinglossdtree)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9561743947897237\n",
            "0.6980553120732594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V856yvEDGhQC",
        "colab_type": "text"
      },
      "source": [
        "**Analysis of Dtree**\n",
        "\n",
        "Iteration 1 - \n",
        "\n",
        "\n",
        "1.0\n",
        "\n",
        "0.1992289373083762\n",
        "\n",
        "This means that the tree is showing no training loss, means it fits the training data 100% but performs very poorly on test data, this is another way of detecting variance.\n",
        "\n",
        "---\n",
        "\n",
        "Iteration 2 -\n",
        "\n",
        "0.9997253857001949\n",
        "\n",
        "0.4521182121500316\n",
        "\n",
        "When we reduced the complexity of the tree to a max depth of 25 levels immediately we see a drop in ability to fit data but we see a substantial increase in ability to predict test data, this is the justification that variance has reduced in our model\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Iteration 3- max depth 15\n",
        "\n",
        "0.9557919969594201\n",
        "\n",
        "0.7201287095240858\n",
        "\n",
        "\n",
        "By reduct depth of tree to 15, we have marginally reduced the training accuracy but signifianctly gained prediction accuracy. This is a good tradeoff\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**THE DEVIL OF DATA**\n",
        "\n",
        "Now i re-split the data by executing the train test split method above, the same model that was giving us excellent result of ~71% now performs poorly on new data.\n",
        "\n",
        "0.9561743947897237\n",
        "\n",
        "0.6980553120732594\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6_9m5RRI85E",
        "colab_type": "text"
      },
      "source": [
        "**let's save the current model and test if on different data**\n",
        "\n",
        "I will save the model\n",
        "Run the split again\n",
        "Import the saved model \n",
        "Test it on the new data\n",
        "Asses results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNt7xOYGGc4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'dtree.sav'\n",
        "pickle.dump(dtree, open(filename, 'wb'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX-1aW7tIuz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80df9c3e-4dc5-428d-d4a1-3589d3da69df"
      },
      "source": [
        "loaded_dtree = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_dtree.score(xtest, ytest)\n",
        "print(result)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9379607777538903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JR0JYZ7JMYE",
        "colab_type": "text"
      },
      "source": [
        "As you can see above that the exported model which was earlier performing poorly, is not giving accuracy of 0.9665740174940533 on test data.\n",
        "\n",
        "--- \n",
        "\n",
        "On repeating the steps again the model gives an accuracy of \n",
        "0.9379607777538903\n",
        "\n",
        "This is a problem of variance that complex models will show, they perform poorly or unpredictably when data changes, this can be a huge issue to compensate in production. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryfMQy0TLFgx",
        "colab_type": "text"
      },
      "source": [
        "Visualising your Dtrees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5JEcyDAKC30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sklearn has a plot_tree function to plot trees in terminal\n",
        "#for larger trees without pruning, the execution will take 5-10mins\n",
        "#if the tree is big then you won't be able to see individual node parameters\n",
        "#for detailed visualisation you can use Graphviz library for quick results\n",
        "\n",
        "\n",
        "print(plot_tree(dtree))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uzfu2LGKGFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7c5d30f-103f-40eb-c5cf-215ee47b9cbd"
      },
      "source": [
        "#using Graphviz\n",
        "#these processes can take a long time to generate the tree, patience please\n",
        "\n",
        "\n",
        "dot = export_graphviz(dtree,\n",
        "                        out_file=None,\n",
        "                        filled=True,\n",
        "                        impurity=None,\n",
        "                        )\n",
        "\n",
        "graph = graphviz.Source(dot)\n",
        "graph.render(\"dtree_render\")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dtree_render.pdf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG-cSMnuQeuU",
        "colab_type": "text"
      },
      "source": [
        "# Ensembling\n",
        "\n",
        "Ensembling is the process of building many smaller models also known as stumps that fit a fragment of your data but working together can as an aggregated model output perform much better than a single complex model\n",
        "\n",
        "--- \n",
        "\n",
        "Let's first try Gradient Boosting Ensembler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZamdNWGModm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4c68596b-9d29-458c-9a0b-71cae36a5722"
      },
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators = 1000, learning_rate = 0.03)\n",
        "\n",
        "gbr.fit(xtrain,ytrain)\n",
        "\n",
        "#ransacR.score(xtrain,ytrain)\n",
        "traininglossgbr = gbr.score(xtrain,ytrain)\n",
        "testinglossgbr = gbr.score(xtest,ytest)\n",
        "\n",
        "print(traininglossgbr)\n",
        "print(testinglossgbr)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8436330872295212\n",
            "0.8201898250992561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAscv5nGRNdY",
        "colab_type": "text"
      },
      "source": [
        "**In here we do not know what the correct number of estimators or sub-models we want, hence let us cycle through a list with options**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhWYYPH3SCxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "72ec423e-2ba0-4bc3-dc68-cdbc8c3ca0e9"
      },
      "source": [
        "argumentlist = [100,200,300,400,500,600,700,800,1000]\n",
        "scorelist = []\n",
        "\n",
        "for i in argumentlist:\n",
        "  gbr = GradientBoostingRegressor(n_estimators = i, learning_rate = 0.03)\n",
        "  gbr.fit(xtrain,ytrain)  \n",
        "  score_to_append = gbr.score(xtest,ytest)\n",
        "  print(score_to_append)\n",
        "  scorelist.append(score_to_append)\n",
        "  \n",
        "  \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(scorelist, argumentlist, label='score')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6067953634273251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7390212254837795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7816154162537913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7970717835245664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8091488953687959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8127816848585412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8171649760612585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8173587070462222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8201898250992563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2550ab0668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0DAX6BMTBaY",
        "colab_type": "text"
      },
      "source": [
        "The above plot gives us an understanding of how the score changes for each selection of estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcbHnZrnSljT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c1e16ad-d283-4f42-e702-88bf9e9644c0"
      },
      "source": [
        "#Now let's check variance of GBR by running split statement and then assesing score\n",
        "\n",
        "\n",
        "#splitting the data\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 30)\n",
        "\n",
        "print(gbr.score(xtest,ytest))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9189803433390424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58nqQLaQTih6",
        "colab_type": "text"
      },
      "source": [
        "Split 1 - 0.9253486080131357\n",
        "\n",
        "Split 2 - 0.8967617652947449\n",
        "\n",
        "Split 3 - 0.771234655801339\n",
        "\n",
        "Split 4 - 0.9189803433390424\n",
        "\n",
        "---\n",
        "\n",
        "The model shows some variance as we change the data."
      ]
    }
  ]
}